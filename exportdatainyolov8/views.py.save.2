from django.http import JsonResponse
from django.views import View
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from LabelCarftProjectSetup.models import Material, Toxicity, Condition, Grade, WasteType
from storeCategoryData.models import CategoryImage, ImageLabel
import yaml
import random
import requests
import os
from pathlib import Path
import zipfile
from django.http import FileResponse
from django.conf import settings
import json
from django.http import StreamingHttpResponse
from .tasks import generate_yolo_dataset
import time
import mimetypes
from django.http import HttpResponse
import traceback
import sys
sys.stdout.reconfigure(encoding='utf-8')
import tensorflow as tf
import mimetypes
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from django.views.decorators.csrf import csrf_exempt
from PIL import Image
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
from sklearn.metrics.pairwise import cosine_similarity
import requests
import numpy as np
import aiohttp
import asyncio
from PIL import Image
from io import BytesIO
import firebase_admin
from .databaseurls import FIREBASE_DB_MAP
from rest_framework.views import APIView
from rest_framework.response import Response
from firebase_admin import credentials
from firebase_admin import db, storage
from rest_framework.permissions import AllowAny
from datetime import datetime
from datetime import timedelta
from rest_framework import status
cred = credentials.Certificate("exportdatainyolov8/cert.json")

def read_in_chunks(file_path, chunk_size=1024):
    """Generator to read a file in chunks."""
    with open(file_path, 'rb') as f:
        print(chunk)
        while chunk := f.read(chunk_size):
            yield chunk


def get_range_header(range_header, file_size):
    """
    Parse the Range header from the request to determine the start and end bytes.
    """
    if not range_header:
        return 0, file_size - 1

    range_value = range_header.strip().replace("bytes=", "")
    start, end = range_value.split("-")

    start = int(start) if start else 0
    end = int(end) if end else file_size - 1

    return start, end




@method_decorator(csrf_exempt, name='dispatch')
class DatasetDownloadView(View):
    def post(self, request, *args, **kwargs):
        try:
            body = json.loads(request.body)
        except json.JSONDecodeError:
            return JsonResponse({'error': 'Invalid JSON'}, status=400)

        category_id = body.get('category_id')
        category_name = body.get('category_name')
        train_images_num = body.get('train_count')
        val_images_num = body.get('val_count')
        test_images_num = body.get('test_count')
        is_blur = body.get('blur_images')
        print(is_blur, "isblut")

        # Call Celery task for background processing
        result = generate_yolo_dataset.apply_async(
            args=[category_id, category_name, train_images_num, val_images_num, test_images_num, is_blur]
        )

        # Respond immediately with task ID
        return JsonResponse({'task_id': result.id}, status=202)



@method_decorator(csrf_exempt, name='dispatch')
class TotalImagesByCategoryView(View):
    def get(self, request, *args, **kwargs):
        # Get the category ID from the request
        category_id = request.GET.get('category_id')

        # Check if category_id is provided
        if not category_id:
            return JsonResponse({'error': 'category_id is required'}, status=400)

        # Get the total number of images for the given category ID
        total_images = CategoryImage.objects.filter(category_id=category_id).count()

        # Return the total number of images as JSON response
        return JsonResponse({'category_id': category_id, 'total_images': total_images})



@method_decorator(csrf_exempt, name='dispatch')
class TaskStatusView(View):
    def get(self, request, *args, **kwargs):
        task_id = request.GET.get('task_id')

        if not task_id:
            return JsonResponse({'error': 'task_id is required'}, status=400)

        # Check the task status
        result = generate_yolo_dataset.AsyncResult(task_id)

        if result.ready():
            task_result = result.result
            if 'success' in task_result:
                file_path = os.path.join(settings.BASE_DIR, 'dataset', 'yolo_dataset.zip')
                if not os.path.exists(file_path):
                    return JsonResponse({'error': 'File not found'}, status=404)

                # Handle range requests
                file_size = os.path.getsize(file_path)
                range_header = request.headers.get("Range")
                start, end = get_range_header(range_header, file_size)

                chunk_size = end - start + 1
                response = HttpResponse(
                    open(file_path, 'rb').read()[start:end + 1],
                    status=206,
                    content_type=mimetypes.guess_type(file_path)[0] or "application/octet-stream"
                )
                response['Content-Range'] = f'bytes {start}-{end}/{file_size}'
                response['Accept-Ranges'] = 'bytes'
                response['Content-Length'] = chunk_size
                response['Content-Disposition'] = 'attachment; filename="yolo_dataset.zip"'
                return response
            else:
                return JsonResponse({'error': 'Dataset generation failed'}, status=500)
        else:
            # Progress handling logic remains unchanged
            progress = result.info  # This contains the `processed` and `total` values
            processed = progress.get('processed', 0)
            percent = int(progress.get('percent', 0))
            total = progress.get('total', 0)
            if percent > 99:
                percent = 99
            return JsonResponse({
                'status': 'In progress',
                'processed': processed,
                'percent': percent,
                'total': total
            }, status=202)



# âœ… Load EfficientNetB5 model (without top classification layer)
model = EfficientNetB0(weights="imagenet", include_top=False, pooling="avg",)


def load_image_from_url(image_url):
    try:
        response = requests.get(image_url, timeout=10)
        response.raise_for_status()
        img = Image.open(BytesIO(response.content)).convert("RGB")
        return img  # Return in-memory PIL image
    except Exception as e:
        print(f"Error loading {image_url}: {e}")
        return None  # Return None if failed


# âœ… Function to Extract Feature Vector (Thread-Safe)
def extract_features(img):
    img = img.resize((240,240))  # Resize for EfficientNet
    img_array = np.array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array = preprocess_input(img_array)
    features = model.predict(img_array)
    return features.flatten()  # Return 1D feature vector


def extract_features_batch(imgs):
    """Extracts features for a batch of images."""
    img_arrays = [np.array(img.resize((240, 240))) for img in imgs]
    img_arrays = np.array(img_arrays)  # Convert to NumPy array
    img_arrays = preprocess_input(img_arrays)

    features = model.predict(img_arrays)
    return features  # Return batch of feature vectors



async def fetch_image(url, session):
    """Fetches an image asynchronously."""
    try:
        async with session.get(url, timeout=5) as response:
            response.raise_for_status()
            img = Image.open(BytesIO(await response.read())).convert("RGB")
            return img
    except Exception as e:
        print(f"âŒ Error loading {url}: {e}")
        return None

async def load_images_async(image_urls):
    """Loads multiple images asynchronously."""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_image(url, session) for url in image_urls]
        return await asyncio.gather(*tasks)

def load_images(image_urls):
    """Wrapper function to run asyncio event loop."""
    return asyncio.run(load_images_async(image_urls))


def process_image_batch(img_urls, house_features):
    """Loads multiple images, extracts features, and computes similarity in a batch."""

    imgs = load_images(img_urls)
    imgs = [img for img in imgs if img is not None]  # âœ… Remove None values

    if not imgs:
        return {}  # Return empty dict if all images failed

    img_features = extract_features_batch(imgs)  # Extract batch features

    similarities = {}
    if img_features.size > 0:  # âœ… Fix: Ensure features exist
        for i, img_url in enumerate(img_urls):
            if i < len(img_features):
                similarity = cosine_similarity([house_features], [img_features[i]])[0][0]
                similarities[img_url] = similarity  # Store similarity score

    return similarities


# âœ… Function to Process a Single Image (Parallel Execution)
def process_image(img_url, house_features):
    """Downloads an image, extracts features, and computes similarity."""
    img = load_image_from_url(img_url)  # Load image in memory
    if img is None:
        return None, None  # Skip if image fails to load
    img_features = extract_features(img)  # Extract features
    similarity = cosine_similarity([house_features], [img_features])[0][0]
    return img_url, similarity  # Return similarity score

try:
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
except AttributeError:
    pass  # Ignore if running on Linux/Mac
# âœ… Django View with Multi-Threading for Faster Execution


@method_decorator(csrf_exempt, name='dispatch')
class ProcessImageTask(View):
    def post(self, request, *args, **kwargs):
        try:
            data = json.loads(request.body)  # Parse JSON request
            house_image_url = data.get("houseImage")
            image_urls = data.get("imageUrls", [])

            if not house_image_url or not image_urls:
                return JsonResponse({"error": "Missing houseImage or imageUrls"}, status=400)

            print("ğŸ”¹ Received House Image URL:", house_image_url)
            print("ğŸ”¹ Received Image URLs:", len(image_urls))

            # âœ… Load House Image & Extract Features
            house_img = load_image_from_url(house_image_url)
            if house_img is None:
                return JsonResponse({"error": "Failed to load houseImage"}, status=400)

            house_features = extract_features(house_img)

            # âœ… Process images in batches
            batch_size = 10  # Adjust based on performance
            similarities = {}

            with ThreadPoolExecutor(max_workers=4) as executor:  # Use 4 threads
                futures = [
                    executor.submit(process_image_batch, image_urls[i:i + batch_size], house_features)
                    for i in range(0, len(image_urls), batch_size)
                ]

                # Collect results
                for future in futures:
                    similarities.update(future.result())

            # âœ… Sort by Similarity (Top 5 matches)
            top_5_images = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:5]
            top_5_images = [img_url for img_url, _ in top_5_images]

            print("ğŸ”¹ Top 5 Similar Images:", top_5_images)

            return JsonResponse({
                "success": True,
                "message": "Top 5 similar images found",
                "top_images": top_5_images
            }, status=200)

        except json.JSONDecodeError:
K


class GetDataForMonitoringTeamWasteCollectionApi(APIView):
    permission_classes = [AllowAny]

    # Helper function to calculate work time

    def convert_to_12hr_format(self,time_str):
        try:
            # Try parsing the time assuming it's in HH:MM format (24-hour)
            time_obj = datetime.strptime(time_str, "%H:%M")
            return time_obj.strftime("%I:%M %p")  # Convert to 12-hour format with AM/PM
        except ValueError:
            return time_str  # Return the original value if the format is invalid
    def calculate_work_time(self, duty_in_time, duty_out_time):
        if not duty_in_time or not duty_out_time:
            return ""
        fmt = "%H:%M"
        try:
            in_time = datetime.strptime(duty_in_time, fmt)
            out_time = datetime.strptime(duty_out_time, fmt)
            if out_time < in_time:
                out_time += timedelta(days=1)
            duration = out_time - in_time
            hours, remainder = divmod(duration.seconds, 3600)
            minutes = remainder // 60
            return f"{hours}h {minutes}m"
        except Exception:
            return ""

    def post(self, request, *args, **kwargs):
        # Default date: yesterday
        date = (datetime.today() - timedelta(days=1)).strftime("%Y-%m-%d")
        city = request.data.get('city', 'nawa')
        date = request.data.get('date', date)

        if not city or city.lower() not in FIREBASE_DB_MAP:
            return Response({'error': 'Invalid or missing city'}, status=status.HTTP_400_BAD_REQUEST)

        db_name = FIREBASE_DB_MAP[city.lower()]
        database_url = f'https://{db_name}.firebaseio.com/'
        app_name = f'app_{db_name}'

        if not firebase_admin._apps.get(app_name):
            firebase_admin.initialize_app(cred, {
                'databaseURL': database_url
            }, name=app_name)

        app = firebase_admin.get_app(app_name)

        try:
            year, month_num, day = date.split("-")
        except ValueError:
            return Response({'error': "Invalid date format. Use YYYY-MM-DD."}, status=status.HTTP_400_BAD_REQUEST)

        month_name_map = {
            "01": "January", "02": "February", "03": "March", "04": "April",
            "05": "May", "06": "June", "07": "July", "08": "August",
            "09": "September", "10": "October", "11": "November", "12": "December"
        }
        month_name = month_name_map.get(month_num)
        if not month_name:
            return Response({'error': 'Invalid month in date.'}, status=status.HTTP_400_BAD_REQUEST)

        formatted_data = []

        # Fetch all zones
        zones_ref_path = f'WasteCollectionInfo'
        zones_ref = db.reference(zones_ref_path, app=app)
        zones_list = zones_ref.get(shallow=True)  # âœ… Only keys, no big data

        if not zones_list:
            return Response([], status=status.HTTP_200_OK)

        for zone in zones_list.keys():
            # Now directly go to required path: zone/year/month/date
            date_ref_path = f'WasteCollectionInfo/{zone}/{year}/{month_name}/{date}'
            date_ref = db.reference(date_ref_path, app=app)
            date_details = date_ref.get()

            if not date_details:
                continue

            worker_details = date_details.get("WorkerDetails", {})
            line_status = date_details.get("LineStatus", {})
            summary = date_details.get("Summary", {})

            vehicle = worker_details.get("vehicle", "")
            driver_id = worker_details.get("driver", "")
            helper_id = worker_details.get("helper", "")
            second_helper_id = worker_details.get("secondHelper", "")

            duty_in_time = summary.get("dutyInTime", "")
            duty_out_time = summary.get("dutyOutTime", "")
            trip = summary.get('trip', '')

            work_time = self.calculate_work_time(
                summary.get("dutyInTime", ""), summary.get("dutyOutTime", "")
            )

            run_km = f'LocationHistory/{zone}/{year}/{month_name}/{date}'
            run_km = db.reference(run_km, app=app)
            run_km = run_km.get()
            from datetime import datetime as dt, timedelta

            def parse_time_to_datetime(tstr, base_date):
            try:
                t = dt.strptime(tstr.strip(), "%H:%M").time()
                return dt.combine(base_date, t)
            except:
                return None 

            entry = {
                "Date": date,
                "City": city,
                "Zone": zone,
                "Start Time": self.convert_to_12hr_format(summary.get("dutyInTime", "")),
                "End Time": self.convert_to_12hr_format(summary.get("dutyOutTime", "")),
                "Vehicle": vehicle,
                "Driver Employee Id": driver_id,
                "Helper Employee Id": helper_id,
                'trip': trip,
                "Second Helper Employee Id": second_helper_id,
                "Work Time": work_time,
                "Work Percentage": summary.get("workPercentage", ""),
                "Run KM": f"{run_km / 1000} km" if run_km else "",  # Convert to kilometers
                "Zone Run KM": f"{summary.get('wardCoveredDistance', 0) / 1000} km" if summary.get(
                "wardCoveredDistance") else "",  # Convert to kilometers
                "Remark": summary.get("remark", ""),

            }

            formatted_data.append(entry)

            # if isinstance(line_status, list):
            #     for trip_data in line_status:
            #         print(trip_data)
            #         if trip_data == None:
            #             continue
            #         # Assuming each entry is a dictionary, e.g., {'Status': 'LineCompleted', 'line-distance': '125'}
            #         entry = {
            #             "Date": date,
            #             "City": city,
            #             "Zone": zone,
            #             "Start Time": trip_data.get("start-time", ""),
            #             "End Time": trip_data.get("end-time", ""),
            #             "Vehicle": vehicle,
            #             "Driver Employee Id": driver_id,
            #             "Helper Employee Id": helper_id,
            #             "Second Helper Employee Id": second_helper_id,
            #             "Status": trip_data.get("Status", ""),
            #             "Line Distance": trip_data.get("line-distance", ""),
            #             "Work Time": work_time,
            #             "Work Percentage": summary.get("workPercentage", ""),
            #             "Run KM": summary.get("runKm", ""),
            #             "Zone Run KM": summary.get("zoneRunKm", ""),
            #             "Remark": summary.get("remark", ""),
            #             'trip':trip
            #         }
            #
            # else:
            #     # Log or skip if it's not a list
            #     print(f"Unexpected line_status type for zone {zone} on {date}: {type(line_status)}")

        return Response(formatted_data, status=s



class GetDataForMonitoringTeamWasteCollectionAllCityApi(APIView):
    permission_classes = [AllowAny]

    # Helper function to calculate work time

    def convert_to_12hr_format(self,time_str):
        try:
            # Try parsing the time assuming it's in HH:MM format (24-hour)
            time_obj = datetime.strptime(time_str, "%H:%M")
            return time_obj.strftime("%I:%M %p")  # Convert to 12-hour format with AM/PM
        except ValueError:
            return time_str  # Return the original value if the format is invalid
    def calculate_work_time(self, duty_in_time, duty_out_time):
        if not duty_in_time or not duty_out_time:
            return ""
        fmt = "%H:%M"
        try:
            in_time = datetime.strptime(duty_in_time, fmt)
            out_time = datetime.strptime(duty_out_time, fmt)
            if out_time < in_time:
                out_time += timedelta(days=1)
            duration = out_time - in_time
            hours, remainder = divmod(duration.seconds, 3600)
            minutes = remainder // 60
            return f"{hours}h {minutes}m"
        except Exception:
            return ""

    def post(self, request, *args, **kwargs):
        # Default date: yesterday
        date = (datetime.today() - timedelta(days=1)).strftime("%Y-%m-%d")
        date = request.data.get('date', date)

        # If no city is specified, fetch data for all cities
        cities_to_fetch = FIREBASE_DB_MAP.keys()

        all_data = []

        for city in cities_to_fetch:
            db_name = FIREBASE_DB_MAP[city]
            database_url = f'https://{db_name}.firebaseio.com/'
            app_name = f'app_{db_name}'

            if not firebase_admin._apps.get(app_name):
                firebase_admin.initialize_app(cred, {
                    'databaseURL': database_url
                }, name=app_name)

            app = firebase_admin.get_app(app_name)

            try:
                year, month_num, day = date.split("-")
            except ValueError:
                return Response({'error': "Invalid date format. Use YYYY-MM-DD."}, status=status.HTTP_400_BAD_REQUEST)

            month_name_map = {
                "01": "January", "02": "February", "03": "March", "04": "April",
                "05": "May", "06": "June", "07": "July", "08": "August",
                "09": "September", "10": "October", "11": "November", "12": "December"
            }
            month_name = month_name_map.get(month_num)
            if not month_name:
                return Response({'error': 'Invalid month in date.'}, status=status.HTTP_400_BAD_REQUEST)

            formatted_data = []

            # Fetch all zones
            zones_ref_path = f'WasteCollectionInfo'
            zones_ref = db.reference(zones_ref_path, app=app)
            zones_list = zones_ref.get(shallow=True)  # âœ… Only keys, no big data

            if not zones_list:
                continue  # Skip if no zones are found

            for zone in zones_list.keys():
                # Now directly go to required path: zone/year/month/date
                date_ref_path = f'WasteCollectionInfo/{zone}/{year}/{month_name}/{date}'
                date_ref = db.reference(date_ref_path, app=app)
                date_details = date_ref.get()

                if not date_details:
                    continue
                print('hello')

                worker_details = date_details.get("WorkerDetails", {})
                line_status = date_details.get("LineStatus", {})
                summary = date_details.get("Summary", {})

                vehicle = worker_details.get("vehicle", "")
                driver_id = worker_details.get("driver", "")
                helper_id = worker_details.get("helper", "")
                second_helper_id = worker_details.get("secondHelper", "")

                duty_in_time = summary.get("dutyInTime", "")
                duty_out_time = summary.get("dutyOutTime", "")
                trip = summary.get('trip', '')

                work_time = self.calculate_work_time(
                    summary.get("dutyInTime", ""), summary.get("dutyOutTime", "")
                )

                run_km = f'LocationHistory/{zone}/{year}/{month_name}/{date}/TotalCoveredDistance'
                run_km = db.reference(run_km, app=app)
                run_km = run_km.get()

                entry = {
                    "Date": date,
                    "City": city,
                    "Zone": zone,
                    "Start Time": self.convert_to_12hr_format(summary.get("dutyInTime", "")),
                    "End Time": self.convert_to_12hr_format(summary.get("dutyOutTime", "")),
                    "Vehicle": vehicle,
                    "Driver Employee Id": driver_id,
                    "Helper Employee Id": helper_id,
                    'trip': trip,
                    "Second Helper Employee Id": second_helper_id,
                    "Work Time": work_time,
                    "Work Percentage": summary.get("workPercentage", ""),
                    "Run KM": f"{run_km / 1000} km" if run_km else "",  # Convert to kilometers
                    "Zone Run KM": f"{summary.get('wardCoveredDistance', 0) / 1000} km" if summary.get(
                        "wardCoveredDistance") else "",  # Convert to kilometers
                    "Remark": summary.get("remark", ""),
                }

                formatted_data.append(entry)

            all_data.extend(formatted_data)  # Add the data of the current city to the overall result

        return Response(all_data, status=status.HTTP_200_OK)
